{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fl-bts.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPOeJX8w7r3+DGDLBqipODQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avocadopelvis/BTP/blob/main/brain-tumor-segmentation/fl-bts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVl5qg_BKhxL",
        "outputId": "0ce2cbbb-ef4d-4443-df1f-b77099f0286d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nilearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnrQ6i33VEEs",
        "outputId": "cb65b09f-2609-4f39-f232-366e67fbea50"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nilearn\n",
            "  Downloading nilearn-0.9.1-py3-none-any.whl (9.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.6 MB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2 in /usr/local/lib/python3.7/dist-packages (from nilearn) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.21.6)\n",
            "Requirement already satisfied: nibabel>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from nilearn) (3.0.2)\n",
            "Requirement already satisfied: joblib>=0.15 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.7.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from nilearn) (4.9.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.0.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->nilearn) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->nilearn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0->nilearn) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->nilearn) (3.1.0)\n",
            "Installing collected packages: nilearn\n",
            "Successfully installed nilearn-0.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "# glob (short for global) is used to return all file paths that match a specific pattern.\n",
        "import glob \n",
        "\n",
        "# PIL adds image processing capabilities to your Python interpreter.\n",
        "import PIL\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "# Shutil module offers high-level operation on a file like a copy, create, and remote operation on the file.\n",
        "import shutil\n",
        "\n",
        "# skimage is a collection of algorithms for image processing and computer vision.\n",
        "from skimage import data\n",
        "from skimage.util import montage\n",
        "import skimage.transform as skTrans\n",
        "from skimage.transform import rotate\n",
        "from skimage.transform import resize\n",
        "\n",
        "\n",
        "# NEURAL IMAGING\n",
        "import nilearn as nl\n",
        "import nibabel as nib # access a multitude of neuroimaging data formats\n",
        "# import nilearn.plotting as nlplt\n",
        "# import gif_your_nifti.core as gif2nif\n",
        "\n",
        "\n",
        "# ML Libraries\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.callbacks import CSVLogger\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "# make numpy printouts easier to read\n",
        "np.set_printoptions(precision = 3, suppress = True)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "A_4xGJxhNsZv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset path\n",
        "train_data = \"/content/drive/MyDrive/BTP/BRAIN TUMOR SEGMENTATION/DATASET/BraTS 2020/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/\"\n",
        "valid_data = \"/content/drive/MyDrive/BTP/BRAIN TUMOR SEGMENTATION/DATASET/BraTS 2020/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData/\""
      ],
      "metadata": {
        "id": "erTTPBpVNW2w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of directories\n",
        "train_val_directories = [f.path for f in os.scandir(train_data) if f.is_dir()]\n",
        "\n",
        "# remove BraTS20_Training_355 since it has ill formatted name for seg.nii file\n",
        "train_val_directories.remove(train_data + 'BraTS20_Training_355')\n",
        "\n",
        "# function to convert list of paths into IDs\n",
        "def pathListIntoIDs(dirList):\n",
        "  x = []\n",
        "  for i in range(0, len(dirList)):\n",
        "    x.append(dirList[i][dirList[i].rfind('/')+1:])\n",
        "  return x\n",
        "\n",
        "ids = pathListIntoIDs(train_val_directories)\n",
        "\n",
        "# split ids into train+test and validation\n",
        "train_test_ids, val_ids = train_test_split(ids, test_size = 0.2)\n",
        "# split train+test into train and test                                           \n",
        "train_ids, test_ids = train_test_split(train_test_ids, test_size = 0.15)"
      ],
      "metadata": {
        "id": "YTuVKntPNrNP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_ids size is 249\n",
        "# break train_ids into 3 parts\n",
        "# size = 249/3 = 82"
      ],
      "metadata": {
        "id": "ydy0jtj3Ol-p"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_client(data, num_clients, initial = 'clients'):\n",
        "  # size of data shard\n",
        "  size = len(data)//num_clients\n",
        "  shards = [data[i:i+size] for i in range(0, len(data), size)]"
      ],
      "metadata": {
        "id": "-52oxpU3PRDH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define segmentation areas\n",
        "SEGMENT_CLASSES = {\n",
        "    0 : 'NOT TUMOR',\n",
        "    1 : 'NECROTIC/CORE', # or NON-ENHANCING TUMOR CORE\n",
        "    2 : 'EDEMA',\n",
        "    3 : 'ENHANCING' # original 4 -> converted into 3 later\n",
        "}\n",
        "\n",
        "# ????????\n",
        "# there are 155 slices per volume\n",
        "# to start at 5 and use 145 slices means we will skip the first 5 and last 5 \n",
        "VOLUME_SLICES = 100 \n",
        "VOLUME_START_AT = 22 # first slice of volume that we will include\n",
        "IMG_SIZE = 128\n",
        "\n",
        "# override keras sequence DataGenerator class\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "    # generates data for Keras\n",
        "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n",
        "        # Initialization\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # denotes the number of batches per epoch\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # generate one batch of data\n",
        "\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(Batch_ids)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # updates indexes after each epoch\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, Batch_ids):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # initialization\n",
        "        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
        "        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n",
        "        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n",
        "\n",
        "        \n",
        "        # Generate data\n",
        "        for c, i in enumerate(Batch_ids):\n",
        "            case_path = os.path.join(train_data, i)\n",
        "\n",
        "            data_path = os.path.join(case_path, f'{i}_flair.nii');\n",
        "            flair = nib.load(data_path).get_fdata()    \n",
        "\n",
        "            data_path = os.path.join(case_path, f'{i}_t1ce.nii');\n",
        "            ce = nib.load(data_path).get_fdata()\n",
        "            \n",
        "            data_path = os.path.join(case_path, f'{i}_seg.nii');\n",
        "            seg = nib.load(data_path).get_fdata()\n",
        "        \n",
        "            for j in range(VOLUME_SLICES):\n",
        "                 X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
        "                 X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
        "\n",
        "                 y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n",
        "                    \n",
        "        # Generate masks\n",
        "        y[y==4] = 3;\n",
        "        mask = tf.one_hot(y, 4);\n",
        "        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n",
        "        return X/np.max(X), Y"
      ],
      "metadata": {
        "id": "bvtChsUlUrpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training_generator = DataGenerator(train_ids)\n",
        "# valid_generator = DataGenerator(val_ids)\n",
        "# test_generator = DataGenerator(test_ids)"
      ],
      "metadata": {
        "id": "YGK8L_3zV3vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to take in client data and create a data generator\n",
        "def create_data_generator(data):\n",
        "  generator = DataGenerator(data)\n",
        "  return generator"
      ],
      "metadata": {
        "id": "CWjdco56fMUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def create_clients(generator, num_clients=10, initial='clients'):\n",
        "    ''' return: a dictionary with keys clients' names and value as \n",
        "                data shards - tuple of images and label lists.\n",
        "        args: \n",
        "            image_list: a list of numpy arrays of training images\n",
        "            label_list:a list of binarized labels for each image\n",
        "            num_client: number of fedrated members (clients)\n",
        "            initials: the clients'name prefix, e.g, clients_1 \n",
        "            \n",
        "    '''\n",
        "\n",
        "    #create a list of client names\n",
        "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
        "\n",
        "    #randomize the data\n",
        "    data = generator\n",
        "    # random.shuffle(data)\n",
        "\n",
        "    #shard data and place at each client\n",
        "    size = len(data)//num_clients\n",
        "    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
        "\n",
        "    #number of clients must equal number of shards\n",
        "    assert(len(shards) == len(client_names))\n",
        "\n",
        "    return {client_names[i] : shards[i] for i in range(len(client_names))} "
      ],
      "metadata": {
        "id": "y6J7D2f1N_HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# U-NET\n",
        "def build_unet(inputs, ker_init, dropout):\n",
        "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n",
        "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n",
        "    \n",
        "    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n",
        "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
        "    \n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n",
        "    \n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n",
        "    \n",
        "    \n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n",
        "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n",
        "    drop5 = Dropout(dropout)(conv5)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
        "    \n",
        "    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv9))\n",
        "    merge = concatenate([conv1,up], axis = 3)\n",
        "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n",
        "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
        "    \n",
        "    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv)\n",
        "    \n",
        "    return Model(inputs = inputs, outputs = conv10)"
      ],
      "metadata": {
        "id": "wy-uTxmjPSHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n",
        "\n",
        "global_model = build_unet(input_layer, 'he_normal', 0.2)\n",
        "# global_model.compile(\n",
        "#     loss = \"categorical_crossentropy\",\n",
        "#     optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n",
        "#     metrics = ['accuracy', tf.keras.metrics.MeanIoU(num_classes = 4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing]\n",
        "# )\n",
        "global_weights = global_model.get_weights()"
      ],
      "metadata": {
        "id": "luZWJXgHPS4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FZghHlXwPTC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mj1ELJSiPTFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fiF9Lmq2PTII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cMFVwu6bPTK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xBlqQS6HPTN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GRBnitKnPTQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z-5N7KiwPTTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZbNF_U85PTV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ey4NUr8hPTYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "K6M7XwlLOHCg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}