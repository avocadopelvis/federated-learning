{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avocadopelvis/BTP/blob/main/brain-tumor-segmentation/fl-bts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VVl5qg_BKhxL"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "rnrQ6i33VEEs"
      },
      "outputs": [],
      "source": [
        "# !pip install nilearn\n",
        "# !pip install keras_unet_collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A_4xGJxhNsZv"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "import glob \n",
        "\n",
        "# PIL adds image processing capabilities to your Python interpreter.\n",
        "import PIL\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "# Shutil module offers high-level operation on a file like a copy, create, and remote operation on the file.\n",
        "import shutil\n",
        "\n",
        "# skimage is a collection of algorithms for image processing and computer vision.\n",
        "from skimage import data\n",
        "from skimage.util import montage\n",
        "import skimage.transform as skTrans\n",
        "from skimage.transform import rotate\n",
        "from skimage.transform import resize\n",
        "\n",
        "\n",
        "# NEURAL IMAGING\n",
        "import nilearn as nl\n",
        "import nibabel as nib # access a multitude of neuroimaging data formats\n",
        "# import nilearn.plotting as nlplt\n",
        "# import gif_your_nifti.core as gif2nif\n",
        "\n",
        "\n",
        "# ML Libraries\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.callbacks import CSVLogger\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "# make numpy printouts easier to read\n",
        "np.set_printoptions(precision = 3, suppress = True)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "erTTPBpVNW2w"
      },
      "outputs": [],
      "source": [
        "# dataset path\n",
        "train_data = \"/content/drive/MyDrive/BTP/BRAIN TUMOR SEGMENTATION/DATASET/BraTS 2020/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/\"\n",
        "valid_data = \"/content/drive/MyDrive/BTP/BRAIN TUMOR SEGMENTATION/DATASET/BraTS 2020/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YTuVKntPNrNP"
      },
      "outputs": [],
      "source": [
        "# list of directories\n",
        "train_val_directories = [f.path for f in os.scandir(train_data) if f.is_dir()]\n",
        "\n",
        "# remove BraTS20_Training_355 since it has ill formatted name for seg.nii file\n",
        "train_val_directories.remove(train_data + 'BraTS20_Training_355')\n",
        "\n",
        "# function to convert list of paths into IDs\n",
        "def pathListIntoIDs(dirList):\n",
        "  x = []\n",
        "  for i in range(0, len(dirList)):\n",
        "    x.append(dirList[i][dirList[i].rfind('/')+1:])\n",
        "  return x\n",
        "\n",
        "ids = pathListIntoIDs(train_val_directories)\n",
        "\n",
        "# split ids into train+test and validation\n",
        "train_test_ids, val_ids = train_test_split(ids, test_size = 0.2, random_state = 42)\n",
        "# split train+test into train and test                                           \n",
        "train_ids, test_ids = train_test_split(train_test_ids, test_size = 0.15, random_state = 42)\n",
        "\n",
        "# train_ids size is 249\n",
        "# break train_ids into 3 parts\n",
        "# size = 249/3 = 82"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bvtChsUlUrpp"
      },
      "outputs": [],
      "source": [
        "# define segmentation areas\n",
        "SEGMENT_CLASSES = {\n",
        "    0 : 'NOT TUMOR',\n",
        "    1 : 'NECROTIC/CORE', # or NON-ENHANCING TUMOR CORE\n",
        "    2 : 'EDEMA',\n",
        "    3 : 'ENHANCING' # original 4 -> converted into 3 later\n",
        "}\n",
        "\n",
        "# ????????\n",
        "# there are 155 slices per volume\n",
        "# to start at 5 and use 145 slices means we will skip the first 5 and last 5 \n",
        "VOLUME_SLICES = 100 \n",
        "VOLUME_START_AT = 22 # first slice of volume that we will include\n",
        "IMG_SIZE = 128\n",
        "\n",
        "# override keras sequence DataGenerator class\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "    # generates data for Keras\n",
        "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n",
        "        # Initialization\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # denotes the number of batches per epoch\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # generate one batch of data\n",
        "\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(Batch_ids)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # updates indexes after each epoch\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, Batch_ids):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # initialization\n",
        "        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
        "        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n",
        "        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n",
        "\n",
        "        \n",
        "        # Generate data\n",
        "        for c, i in enumerate(Batch_ids):\n",
        "            case_path = os.path.join(train_data, i)\n",
        "\n",
        "            data_path = os.path.join(case_path, f'{i}_flair.nii');\n",
        "            flair = nib.load(data_path).get_fdata()    \n",
        "\n",
        "            data_path = os.path.join(case_path, f'{i}_t1ce.nii');\n",
        "            ce = nib.load(data_path).get_fdata()\n",
        "            \n",
        "            data_path = os.path.join(case_path, f'{i}_seg.nii');\n",
        "            seg = nib.load(data_path).get_fdata()\n",
        "        \n",
        "            for j in range(VOLUME_SLICES):\n",
        "                 X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
        "                 X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
        "\n",
        "                 y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n",
        "                    \n",
        "        # Generate masks\n",
        "        y[y==4] = 3;\n",
        "        mask = tf.one_hot(y, 4);\n",
        "        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n",
        "        return X/np.max(X), Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "LJhvb6Sg2Mx5"
      },
      "outputs": [],
      "source": [
        "# function to take in data and return a dictionary with client names as keys and values as data shards\n",
        "def create_client(data, num_clients, initial = 'client'):\n",
        "  # create a list of client names\n",
        "  client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
        "\n",
        "  # size of data shard\n",
        "  size = len(data)//num_clients\n",
        "  # create data shard for each client\n",
        "  shards = [data[i:i+size] for i in range(0, len(data), size)]\n",
        "\n",
        "  # number of clients must equal number of shards\n",
        "  assert(len(shards) == len(client_names))\n",
        "\n",
        "  return {client_names[i] : shards[i] for i in range(len(client_names))} \n",
        "\n",
        "def weight_scaling_factor(data):\n",
        "    return len(data)/len(train_ids)\n",
        "\n",
        "\n",
        "def scale_model_weights(weight, scalar):\n",
        "    '''function for scaling a models weights'''\n",
        "    weight_final = []\n",
        "    steps = len(weight)\n",
        "    for i in range(steps):\n",
        "        weight_final.append(scalar * weight[i])\n",
        "    return weight_final\n",
        "\n",
        "\n",
        "\n",
        "def sum_scaled_weights(scaled_weight_list):\n",
        "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
        "    avg_grad = list()\n",
        "    #get the average grad accross all client gradients\n",
        "    for grad_list_tuple in zip(*scaled_weight_list):\n",
        "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
        "        avg_grad.append(layer_mean)\n",
        "        \n",
        "    return avg_grad\n",
        "\n",
        "\n",
        "# function to evaluate the model on test data and print the current round and metrics\n",
        "def evaluate_model(data, model, round): \n",
        "  test_generator = DataGenerator(data)\n",
        "  results = model.evaluate(test_generator, batch_size = batch_size, verbose = 1)\n",
        "  loss, accuracy = results[0], results[1]*100\n",
        "  print(f'round: {round} | loss: {loss} | accuracy: {accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tDnYXEEI1jAC"
      },
      "outputs": [],
      "source": [
        "# create clients\n",
        "clients = create_client(train_ids, 3)\n",
        "valid_generator = DataGenerator(val_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Mi-Kg1wfu2tz"
      },
      "outputs": [],
      "source": [
        "# HYPERPARAMETERS\n",
        "from keras_unet_collection import losses\n",
        "\n",
        "loss = \"categorical_crossentropy\",\n",
        "learning_rate = 0.001\n",
        "optimizer = keras.optimizers.Adam(learning_rate = learning_rate)\n",
        "metrics = ['accuracy', losses.dice]\n",
        "\n",
        "# add callback for training process\n",
        "callbacks = [\n",
        "#     keras.callbacks.EarlyStopping(monitor='loss', min_delta=0,\n",
        "#                               patience=2, verbose=1, mode='auto'),\n",
        "      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, \n",
        "                              patience=2, min_lr=0.000001, verbose=1) \n",
        "#  keras.callbacks.ModelCheckpoint(filepath = 'model_.{epoch:02d}-{val_loss:.6f}.m5',\n",
        "#                             verbose=1, save_best_only=True, save_weights_only = True)\n",
        "    ]\n",
        "\n",
        "# number of global epochs\n",
        "rounds = 5\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "PgVTGDpcxV87"
      },
      "outputs": [],
      "source": [
        "from keras_unet_collection import models\n",
        "\n",
        "# U-Net\n",
        "# model = models.unet_2d((IMG_SIZE, IMG_SIZE, 2), [32, 64, 128, 256, 512], 4)\n",
        "# U-Net++\n",
        "# model = models.unet_plus_2d((IMG_SIZE, IMG_SIZE, 2), [32, 64, 128, 256, 512], 4)\n",
        "# Attention U-Net\n",
        "model = models.att_unet_2d((IMG_SIZE, IMG_SIZE, 2), [32, 64, 128, 256, 512], 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "V9EB0OWX1KxB"
      },
      "outputs": [],
      "source": [
        "# initialize global model\n",
        "# global_model = build_unet(input_layer, 'he_normal', 0.2)\n",
        "global_model = model\n",
        "global_model.compile(\n",
        "        loss = loss,\n",
        "        optimizer = optimizer,\n",
        "        metrics = metrics\n",
        "        )\n",
        "print(\"Begin Training\")\n",
        "# commence global training loop\n",
        "for round in range(1, rounds+1):\n",
        "  print(f'\\nRound: {round}')\n",
        "\n",
        "  # get global model's weights\n",
        "  global_weights = global_model.get_weights()\n",
        "\n",
        "  # initial list to collect local model weights after scaling\n",
        "  scaled_local_weight_list = list()\n",
        "\n",
        "  # get client names\n",
        "  client_names= list(clients.keys())\n",
        "  random.shuffle(client_names)\n",
        "\n",
        "  count = 1\n",
        "  # loop through each client and create new local model\n",
        "  for client in client_names:\n",
        "    print(f'Client {count}')\n",
        "    local_model = model\n",
        "    local_model.compile(\n",
        "        loss = loss,\n",
        "        optimizer = optimizer,\n",
        "        metrics = metrics\n",
        "        )\n",
        "    \n",
        "    #set local model weight to the weight of the global model\n",
        "    local_model.set_weights(global_weights)\n",
        "\n",
        "    # get client data and pass it through a data generator\n",
        "    data = DataGenerator(clients[client])\n",
        "\n",
        "    # fit local model with client's data\n",
        "    local_model.fit(data, epochs = 1, steps_per_epoch = len(data), verbose = 1) #callbacks = callbacks, validation_data = valid_generator)\n",
        "\n",
        "    # scale the model weights and add to list\n",
        "    scaling_factor = weight_scaling_factor(data)\n",
        "    scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
        "    \n",
        "    # not adding scaling\n",
        "    scaled_local_weight_list.append(local_model.get_weights())\n",
        "\n",
        "    # clear session to free memory after each communication round\n",
        "    K.clear_session()\n",
        "\n",
        "    count += 1\n",
        "\n",
        "  #to get the average over all the local model, we simply take the sum of the scaled weights\n",
        "  average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
        "      \n",
        "  #update global model \n",
        "  global_model.set_weights(average_weights)\n",
        "\n",
        "  evaluate_model(test_ids, global_model, round)\n",
        "\n",
        "print('\\nTraining Done!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FZghHlXwPTC2"
      },
      "outputs": [],
      "source": [
        "# client_names= list(clients.keys())\n",
        "# for client in client_names:\n",
        "#   print(clients[client])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-k8McR1MBEgv"
      },
      "outputs": [],
      "source": [
        "# client_data = clients['client_1']\n",
        "# data = DataGenerator(client_data)\n",
        "# valid_generator = DataGenerator(val_ids)\n",
        "\n",
        "# local_model = model\n",
        "# local_model.compile(\n",
        "#       loss = loss,\n",
        "#       optimizer = optimizer,\n",
        "#       metrics = metrics\n",
        "#       )\n",
        "\n",
        "# local_model.fit(data, epochs=1, steps_per_epoch=len(data), verbose = 1) # callbacks = callbacks, validation_data = valid_generator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rmAqMbdFkDMF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZK9qzb6h-bC-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pXbgSLKWDVCI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "epd_PfmT-GKl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xBlqQS6HPTN-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GRBnitKnPTQi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Z-5N7KiwPTTK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZbNF_U85PTV5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ey4NUr8hPTYh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "K6M7XwlLOHCg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "fl-bts.ipynb",
      "provenance": [],
      "mount_file_id": "1JhA-UJrQS77d_SsJKsgOTC9Yl5MSx1Hl",
      "authorship_tag": "ABX9TyP4WSqZsydg4SQKAVi9gisY",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}